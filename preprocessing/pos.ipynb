{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import emoji\n",
    "from collections import Counter\n",
    "from scipy.stats import beta\n",
    "from calc_prob import calc_prob_between\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/all-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_codes = {\n",
    "    'english':'en',\n",
    "    'arabic':'ar',\n",
    "    'german':'de',\n",
    "    'indonesian':'id',\n",
    "    'italian':'it',\n",
    "    'portuguese':'pt',\n",
    "    'spanish':'es',\n",
    "    'french':'fr',\n",
    "    'turkish':'tr',\n",
    "    'danish':'da',\n",
    "    'hindi':'hi'\n",
    "}\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "def slice_dataframe_and_compute_word_frequency(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    words = [token.text for token in doc if not token.is_stop and not token.is_punct and len(token) > 1]\n",
    "    freqs = Counter(words)\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    total = 0\n",
    "    for k,v in sorted(pos_counts.items()):\n",
    "        total += v\n",
    "        print(f'{k:{4}}. {doc.vocab[k].text:{5}}: {v}')\n",
    "    print('total', total)\n",
    "    return freqs\n",
    "\n",
    "def slice_dataframe_and_compute_pos_tags(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    nlp.max_length = 4000000 \n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    total = 0\n",
    "    for k,v in sorted(pos_counts.items()):\n",
    "        total += v\n",
    "        # print(f'{k:{4}}. {doc.vocab[k].text:{5}}: {v}')\n",
    "    # print('total', total)\n",
    "    return pos_counts, total\n",
    "\n",
    "def ab_test(imps_ctrl, convs_ctrl, imps_test, convs_test):\n",
    "    a_C, b_C = convs_ctrl+1, imps_ctrl-convs_ctrl+1\n",
    "    beta_C = beta(a_C, b_C)\n",
    "    a_T, b_T = convs_test+1, imps_test-convs_test+1\n",
    "    beta_T = beta(a_T, b_T)\n",
    "\n",
    "    lift=(beta_T.mean()-beta_C.mean())/beta_C.mean()\n",
    "    prob=calc_prob_between(beta_T, beta_C)\n",
    "    # print (f\"Test option lift Conversion Rates by {lift*100:2.2f}% with {prob*100:2.1f}% probability.\")\n",
    "    return lift, prob\n",
    "\n",
    "pos_dict = {'84': 'adjective', '85': 'adposition', '86': 'adverb', '87': 'auxiliary', '89': 'coordinating conjunction', \\\n",
    "'90': 'determiner', '91': 'interjection', '92': 'noun', '93': 'numeral', '94': 'particle', '95': 'pronoun', \\\n",
    "'96': 'proper noun', '97': 'punctuation', '98': 'subordinating conjunction', '99': 'symbol', '100': 'verb', '103': 'space'}\n",
    "\n",
    "def print_pos_stats(df, spacy_pkg):\n",
    "    hs_tags, hs_total = slice_dataframe_and_compute_pos_tags(df, ['hs'], [1], 'text', spacy_pkg)\n",
    "    normal_tags, normal_total = slice_dataframe_and_compute_pos_tags(df, ['hs'], [0], 'text', spacy_pkg)\n",
    "    for k,v in sorted(hs_tags.items()):\n",
    "        try:    \n",
    "            pos = pos_dict[str(k)]\n",
    "            hs_pos_count = v\n",
    "            normal_pos_count = normal_tags[k]\n",
    "            hs_pos_percent = v / hs_total\n",
    "            normal_pos_percent = normal_pos_count / normal_total\n",
    "            lift, prob = ab_test(normal_total, normal_pos_count, hs_total, hs_pos_count)\n",
    "            print(f'| {pos} | {normal_pos_count} | {hs_pos_count} | {normal_pos_percent*100:2.2f}% | {hs_pos_percent*100:2.2f}% | {lift*100:2.2f}% | {prob:2.6f} |')\n",
    "        except Exception:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hateful_sentiment_dict = {}\n",
    "# for path in glob.glob('../data/all-processed/*.csv'):\n",
    "#     try:\n",
    "#         path_in_str = str(path)\n",
    "#         print(path_in_str)\n",
    "#         df = pd.read_csv(path_in_str)\n",
    "#         print_pos_stats(df, 'en_core_web_sm')\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e.with_traceback)\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/B_spanish_pereira_processed.csv')\n",
    "try:\n",
    "    print_pos_stats(df, 'es_core_news_sm')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b9210e76c871583b4be282bfe8fe4a35092a039f09ad1ca55e305e87262e8ac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ai_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
