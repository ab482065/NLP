{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import emoji\n",
    "from collections import Counter\n",
    "from scipy.stats import beta\n",
    "from calc_prob import calc_prob_between\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/all-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_codes = {\n",
    "    'english':'en',\n",
    "    'arabic':'ar',\n",
    "    'german':'de',\n",
    "    'indonesian':'id',\n",
    "    'italian':'it',\n",
    "    'portuguese':'pt',\n",
    "    'spanish':'es',\n",
    "    'french':'fr',\n",
    "    'turkish':'tr',\n",
    "    'danish':'da',\n",
    "    'hindi':'hi'\n",
    "}\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "def slice_dataframe_and_compute_word_frequency(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    words = [token.text for token in doc if not token.is_stop and not token.is_punct and len(token) > 1]\n",
    "    freqs = Counter(words)\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    total = 0\n",
    "    for k,v in sorted(pos_counts.items()):\n",
    "        total += v\n",
    "        print(f'{k:{4}}. {doc.vocab[k].text:{5}}: {v}')\n",
    "    print('total', total)\n",
    "    return freqs\n",
    "\n",
    "def slice_dataframe_and_compute_pos_tags(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    nlp.max_length = 4000000 \n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "    total = 0\n",
    "    for k,v in sorted(pos_counts.items()):\n",
    "        total += v\n",
    "        # print(f'{k:{4}}. {doc.vocab[k].text:{5}}: {v}')\n",
    "    # print('total', total)\n",
    "    return pos_counts, total\n",
    "\n",
    "def ab_test(imps_ctrl, convs_ctrl, imps_test, convs_test):\n",
    "    a_C, b_C = convs_ctrl+1, imps_ctrl-convs_ctrl+1\n",
    "    beta_C = beta(a_C, b_C)\n",
    "    a_T, b_T = convs_test+1, imps_test-convs_test+1\n",
    "    beta_T = beta(a_T, b_T)\n",
    "\n",
    "    lift=(beta_T.mean()-beta_C.mean())/beta_C.mean()\n",
    "    prob=calc_prob_between(beta_T, beta_C)\n",
    "    # print (f\"Test option lift Conversion Rates by {lift*100:2.2f}% with {prob*100:2.1f}% probability.\")\n",
    "    return lift, prob\n",
    "\n",
    "pos_dict = {'84': 'adjective', '85': 'adposition', '86': 'adverb', '87': 'auxiliary', '89': 'coordinating conjunction', \\\n",
    "'90': 'determiner', '91': 'interjection', '92': 'noun', '93': 'numeral', '94': 'particle', '95': 'pronoun', \\\n",
    "'96': 'proper noun', '97': 'punctuation', '98': 'subordinating conjunction', '99': 'symbol', '100': 'verb', '103': 'space'}\n",
    "\n",
    "def print_pos_stats(df, spacy_pkg):\n",
    "    normal_tags, normal_total = slice_dataframe_and_compute_pos_tags(df, ['hs'], [0], 'text', spacy_pkg)\n",
    "    hs_tags, hs_total = slice_dataframe_and_compute_pos_tags(df, ['hs'], [1], 'text', spacy_pkg)\n",
    "    for k,v in sorted(hs_tags.items()):\n",
    "        try:    \n",
    "            pos = pos_dict[str(k)]\n",
    "            hs_pos_count = v\n",
    "            normal_pos_count = normal_tags[k]\n",
    "            hs_pos_percent = v / hs_total\n",
    "            normal_pos_percent = normal_pos_count / normal_total\n",
    "            lift, prob = ab_test(normal_total, normal_pos_count, hs_total, hs_pos_count)\n",
    "            print(f'| {pos} | {normal_pos_count} | {hs_pos_count} | {normal_pos_percent*100:2.2f}% | {hs_pos_percent*100:2.2f}% | {lift*100:2.2f}% | {prob:2.6f} |')\n",
    "        except Exception:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/all-processed\\B_arabic_mulki_processed.csv\n",
      "Found a total of 3649 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F0560FA68>\n",
      "../data/all-processed\\B_danish_processed.csv\n",
      "Found a total of 2850 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F77A6E0D8>\n",
      "../data/all-processed\\B_english_basile_processed.csv\n",
      "Found a total of 7530 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F04668CA8>\n",
      "../data/all-processed\\B_english_davidson_processed.csv\n",
      "Found a total of 4163 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F0435B1F8>\n",
      "../data/all-processed\\B_english_founta_processed.csv\n",
      "Found a total of 34487 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F04406048>\n",
      "../data/all-processed\\B_english_gilbert_processed.csv\n",
      "Found a total of 9507 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F017860D8>\n",
      "../data/all-processed\\B_english_ousidhoum_processed.csv\n",
      "Found a total of 4369 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F03641B88>\n",
      "../data/all-processed\\B_english_waseem_processed.csv\n",
      "Found a total of 7679 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F02502678>\n",
      "../data/all-processed\\B_french_ousidhoum_processed.csv\n",
      "Found a total of 821 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F00BA0048>\n",
      "../data/all-processed\\B_german_bretschneider_processed.csv\n",
      "Found a total of 5141 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F0034DF78>\n",
      "../data/all-processed\\B_german_ross_processed.csv\n",
      "Found a total of 364 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F0034D1F8>\n",
      "../data/all-processed\\B_indonesian_alfina_processed.csv\n",
      "Found a total of 453 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F76851A68>\n",
      "../data/all-processed\\B_indonesian_ibrohim_processed.csv\n",
      "Found a total of 7607 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F0560FD38>\n",
      "../data/all-processed\\B_italian_bosco_processed.csv\n",
      "Found a total of 4071 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F04479C18>\n",
      "../data/all-processed\\B_italian_manuel_processed.csv\n",
      "Found a total of 4436 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F03A693A8>\n",
      "../data/all-processed\\B_portuguese_processed.csv\n",
      "Found a total of 4440 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F05612708>\n",
      "../data/all-processed\\B_spanish_basile_processed.csv\n",
      "Found a total of 3861 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F00B818B8>\n",
      "../data/all-processed\\B_spanish_pereira_processed.csv\n",
      "Found a total of 4433 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F04652438>\n",
      "../data/all-processed\\B_turkish_processed.csv\n",
      "Found a total of 28035 examples\n",
      "<built-in method with_traceback of OSError object at 0x0000020F03A81318>\n"
     ]
    }
   ],
   "source": [
    "hateful_sentiment_dict = {}\n",
    "for path in glob.glob('../data/all-processed/*.csv'):\n",
    "    try:\n",
    "        path_in_str = str(path)\n",
    "        print(path_in_str)\n",
    "        df = pd.read_csv(path_in_str)\n",
    "        print_pos_stats(df, 'tacobell')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.with_traceback)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 4433 examples\n",
      "Found a total of 1567 examples\n",
      "| adjective | 11158 | 3924 | 16.80% | 18.45% | 9.83% | 0.000000 |\n",
      "| adposition | 334 | 62 | 0.50% | 0.29% | -41.28% | 0.000017 |\n",
      "| adverb | 1641 | 485 | 2.47% | 2.28% | -7.58% | 0.058753 |\n",
      "| auxiliary | 932 | 355 | 1.40% | 1.67% | 19.14% | 0.002674 |\n",
      "| coordinating conjunction | 250 | 83 | 0.38% | 0.39% | 4.50% | 0.371782 |\n",
      "| determiner | 544 | 184 | 0.82% | 0.87% | 5.99% | 0.251655 |\n",
      "| interjection | 93 | 26 | 0.14% | 0.12% | -10.31% | 0.293615 |\n",
      "| noun | 14591 | 4707 | 21.97% | 22.13% | 0.74% | 0.309234 |\n",
      "| numeral | 1593 | 386 | 2.40% | 1.82% | -24.19% | 0.000000 |\n",
      "| particle | 3 | 2 | 0.00% | 0.01% | 134.18% | 0.157848 |\n",
      "| pronoun | 378 | 117 | 0.57% | 0.55% | -2.78% | 0.386884 |\n",
      "| proper noun | 9332 | 2623 | 14.05% | 12.33% | -12.21% | 0.000000 |\n",
      "| punctuation | 12655 | 3856 | 19.06% | 18.13% | -4.84% | 0.001317 |\n",
      "| subordinating conjunction | 720 | 192 | 1.08% | 0.90% | -16.42% | 0.011401 |\n",
      "| symbol | 2962 | 1286 | 4.46% | 6.05% | 35.63% | 0.000000 |\n",
      "| verb | 8939 | 2942 | 13.46% | 13.83% | 2.79% | 0.082795 |\n",
      "| space | 284 | 37 | 0.43% | 0.17% | -58.37% | 0.000000 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/B_spanish_pereira_processed.csv')\n",
    "try:\n",
    "    print_pos_stats(df, 'es_core_news_sm')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b9210e76c871583b4be282bfe8fe4a35092a039f09ad1ca55e305e87262e8ac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ai_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
