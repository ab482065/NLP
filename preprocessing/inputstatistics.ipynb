{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e46ba26",
   "metadata": {},
   "source": [
    "# Input Statistical Analysis for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c462db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import emoji\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5214cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cf3e9",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6610e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "def slice_dataframe_and_compute_word_frequency(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    words = [token.text for token in doc if not token.is_stop and not token.is_punct and len(token) > 1]\n",
    "    freqs = Counter(words)\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf033b",
   "metadata": {},
   "source": [
    "### Spanish (Basile et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0fc855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/spanish-basile/hateval2019_es_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dfb4736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>Easyjet quiere duplicar el número de mujeres p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>El gobierno debe crear un control estricto de ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>Yo veo a mujeres destruidas por acoso laboral ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>— Yo soy respetuoso con los demás, sólamente l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20007</td>\n",
       "      <td>Antonio Caballero y como ser de mal gusto e ig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  HS  TR  AG\n",
       "0  20001  Easyjet quiere duplicar el número de mujeres p...   1   0   0\n",
       "1  20002  El gobierno debe crear un control estricto de ...   1   0   0\n",
       "2  20003  Yo veo a mujeres destruidas por acoso laboral ...   0   0   0\n",
       "3  20004  — Yo soy respetuoso con los demás, sólamente l...   0   0   0\n",
       "4  20007  Antonio Caballero y como ser de mal gusto e ig...   0   0   0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0468b6",
   "metadata": {},
   "source": [
    "#### 1.1 Word Frequecy for Examples that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3d13a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 1857 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 418),\n",
       " ('perra', 345),\n",
       " ('zorra', 216),\n",
       " ('Cállate', 122),\n",
       " ('callate', 110),\n",
       " ('inmigrantes', 102),\n",
       " ('mujer', 96),\n",
       " ('Callate', 91),\n",
       " ('mereces', 82),\n",
       " ('cállate', 78)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [1], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0220d",
   "metadata": {},
   "source": [
    "#### 1.2 Word Frequecy for Examples that are Hate Speech and Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee99b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 1502 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 398),\n",
       " ('perra', 322),\n",
       " ('zorra', 207),\n",
       " ('Cállate', 122),\n",
       " ('callate', 109),\n",
       " ('Callate', 90),\n",
       " ('mereces', 80),\n",
       " ('cállate', 78),\n",
       " ('mierda', 74),\n",
       " ('PUTA', 67)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS', 'AG'], [1, 1], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6586a29",
   "metadata": {},
   "source": [
    "#### 1.3 Word Frequecy for Examples that are Hate Speech but not Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "539b5519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 355 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mujer', 54),\n",
       " ('inmigrantes', 36),\n",
       " ('mujeres', 32),\n",
       " ('subsaharianos', 23),\n",
       " ('perra', 23),\n",
       " ('puta', 20),\n",
       " ('España', 17),\n",
       " ('país', 17),\n",
       " ('papeles', 16),\n",
       " ('inmigrante', 15)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS', 'AG'], [1, 0], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a1140",
   "metadata": {},
   "source": [
    "#### 2.  Word Frequecy for Examples that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4fcd9222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 2643 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 784),\n",
       " ('hijo', 237),\n",
       " ('acoso', 198),\n",
       " ('madre', 149),\n",
       " ('perra', 142),\n",
       " ('polla', 141),\n",
       " ('PUTA', 139),\n",
       " ('mierda', 117),\n",
       " ('mereces', 112),\n",
       " ('violación', 110)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [0], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0ff63",
   "metadata": {},
   "source": [
    "### Spanish (Pereira et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc8835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary wrangling to fit it into a DataFrame\n",
    "data = []\n",
    "with open(f'{DATA_DIR}/spanish-pereira/labeled_corpus_6K.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        curr = line.split(\";||;\")\n",
    "        data.append(curr[:-1] + [int(curr[-1][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0665c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.array(data), columns=['id', 'text', 'HS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84386282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HS'] = df.HS.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54bb2c",
   "metadata": {},
   "source": [
    "#### 1. Word Frequecy for Examples that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae2d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                               text  \\\n",
      "0  id=828025263321657348  Ismael es egocentrico porque se vuelve loca si...   \n",
      "1  id=828025128797741057  ..ya tardaba en salir quien pronunciase nombre...   \n",
      "2  id=828025087815274496  (Esto no es un discurso político y razonado, o...   \n",
      "3  id=828025006626058241  Muy despreciados,siiii,pero todos vestidos de ...   \n",
      "4  id=828024709761658880  marica explicame porque a veces no te entiendo...   \n",
      "\n",
      "   HS  \n",
      "0   0  \n",
      "1   0  \n",
      "2   0  \n",
      "3   1  \n",
      "4   1  \n",
      "Found a total of 1567 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('subnormal', 350),\n",
       " ('mierda', 144),\n",
       " ('puto', 97),\n",
       " ('puta', 91),\n",
       " ('fascista', 85),\n",
       " ('fachas', 82),\n",
       " ('facha', 66),\n",
       " ('fascistas', 61),\n",
       " ('nazi', 44),\n",
       " ('retrasado', 42)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [1], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910ad7f",
   "metadata": {},
   "source": [
    "#### 2. Word Frequecy for Examples that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bfa6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                               text  \\\n",
      "0  id=828025263321657348  Ismael es egocentrico porque se vuelve loca si...   \n",
      "1  id=828025128797741057  ..ya tardaba en salir quien pronunciase nombre...   \n",
      "2  id=828025087815274496  (Esto no es un discurso político y razonado, o...   \n",
      "3  id=828025006626058241  Muy despreciados,siiii,pero todos vestidos de ...   \n",
      "4  id=828024709761658880  marica explicame porque a veces no te entiendo...   \n",
      "\n",
      "   HS  \n",
      "0   0  \n",
      "1   0  \n",
      "2   0  \n",
      "3   1  \n",
      "4   1  \n",
      "Found a total of 4433 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('independentista', 501),\n",
       " ('subnormal', 306),\n",
       " ('fascista', 200),\n",
       " ('facha', 196),\n",
       " ('fascistas', 157),\n",
       " ('negro', 145),\n",
       " ('fachas', 135),\n",
       " ('mayoría', 124),\n",
       " ('género', 121),\n",
       " ('gente', 118)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [0], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfeb074",
   "metadata": {},
   "source": [
    "### French (Ousidhoum et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b4dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/french-ousidhoum/fr_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97aefa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>directness</th>\n",
       "      <th>annotator_sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @user personnage ainsi q tte la clique gauc...</td>\n",
       "      <td>abusive</td>\n",
       "      <td>direct</td>\n",
       "      <td>shock</td>\n",
       "      <td>origin</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@user @user @user bah oui t'as raison l'autre ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>indirect</td>\n",
       "      <td>shock</td>\n",
       "      <td>other</td>\n",
       "      <td>individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moi j'ai personne à qui m'adresser pour réclam...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>direct</td>\n",
       "      <td>anger_confusion_sadness_fear_disgust</td>\n",
       "      <td>other</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@user @user c...est vrai que les anchois sont ...</td>\n",
       "      <td>normal</td>\n",
       "      <td>indirect</td>\n",
       "      <td>indifference</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>eh les renois faut se réveiller la @url</td>\n",
       "      <td>normal</td>\n",
       "      <td>direct</td>\n",
       "      <td>sadness</td>\n",
       "      <td>origin</td>\n",
       "      <td>african_descent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HITId                                              tweet  sentiment  \\\n",
       "0      1  rt @user personnage ainsi q tte la clique gauc...    abusive   \n",
       "1      2  @user @user @user bah oui t'as raison l'autre ...  offensive   \n",
       "2      3  moi j'ai personne à qui m'adresser pour réclam...    hateful   \n",
       "3      4  @user @user c...est vrai que les anchois sont ...     normal   \n",
       "4      5            eh les renois faut se réveiller la @url     normal   \n",
       "\n",
       "  directness                   annotator_sentiment  target            group  \n",
       "0     direct                                 shock  origin            other  \n",
       "1   indirect                                 shock   other       individual  \n",
       "2     direct  anger_confusion_sadness_fear_disgust   other            women  \n",
       "3   indirect                          indifference   other            other  \n",
       "4     direct                               sadness  origin  african_descent  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aef7e2",
   "metadata": {},
   "source": [
    "#### 1. Word Frequency for Examples that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "730a3ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 821 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@user', 970),\n",
       " ('@url', 475),\n",
       " ('gauchiste', 93),\n",
       " ('renois', 79),\n",
       " ('attarde', 66),\n",
       " ('migrants', 62),\n",
       " ('violence', 60),\n",
       " ('contre', 53),\n",
       " ('arabes', 43),\n",
       " ('attardé', 42)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['normal'], 'tweet', 'fr_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad692cc",
   "metadata": {},
   "source": [
    "#### 2. Word Frequency for Examples that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ab69fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 594 examples\n",
      "Found a total of 1336 examples\n",
      "Found a total of 207 examples\n",
      "Found a total of 142 examples\n",
      "Found a total of 236 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@url', 335),\n",
       " ('@user', 239),\n",
       " ('mongol', 81),\n",
       " ('gauchiste', 77),\n",
       " ('renois', 74),\n",
       " ('rebeus', 61),\n",
       " ('attardé', 56),\n",
       " ('rt', 44),\n",
       " ('migrants', 35),\n",
       " ('sale', 31)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['abusive'], 'tweet', 'fr_core_news_sm')\n",
    "freqs + slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['offensive'], 'tweet', 'fr_core_news_sm')\n",
    "freqs + slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['hateful'], 'tweet', 'fr_core_news_sm')\n",
    "freqs + slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['disrespectful'], 'tweet', 'fr_core_news_sm')\n",
    "freqs + slice_dataframe_and_compute_word_frequency(df, ['sentiment'], ['fearful'], 'tweet', 'fr_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5e994",
   "metadata": {},
   "source": [
    "### Turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82e3ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/turkish/offenseval-tr-training-v1/offenseval-tr-training-v1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c451f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20948</td>\n",
       "      <td>@USER en güzel uyuyan insan ödülü jeon jungkoo...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10134</td>\n",
       "      <td>@USER Mekanı cennet olsun, saygılar sayın avuk...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23457</td>\n",
       "      <td>Kızlar aranızda kas yığını beylere düşenler ol...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18401</td>\n",
       "      <td>Biraz ders çalışayım. Tembellik ve uyku düşman...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17525</td>\n",
       "      <td>@USER Trezeguet yerine El Sharawy daha iyi olm...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a\n",
       "0  20948  @USER en güzel uyuyan insan ödülü jeon jungkoo...       NOT\n",
       "1  10134  @USER Mekanı cennet olsun, saygılar sayın avuk...       NOT\n",
       "2  23457  Kızlar aranızda kas yığını beylere düşenler ol...       NOT\n",
       "3  18401  Biraz ders çalışayım. Tembellik ve uyku düşman...       NOT\n",
       "4  17525  @USER Trezeguet yerine El Sharawy daha iyi olm...       NOT"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb2a42",
   "metadata": {},
   "source": [
    "#### 1. Word Frequency for tweets that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f11b5978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 6046 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@USER', 5367),\n",
       " ('  ', 1380),\n",
       " ('bir', 1267),\n",
       " ('bu', 1167),\n",
       " ('ve', 847),\n",
       " ('ne', 718),\n",
       " ('de', 688),\n",
       " ('da', 660),\n",
       " ('için', 546),\n",
       " ('gibi', 528)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['subtask_a'], ['OFF'], 'tweet', 'en_core_web_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7bf92",
   "metadata": {},
   "source": [
    "#### 2. Word Frequency for tweets that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is too long for Spacy. DON'T RUN\n",
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['subtask_a'], ['NOT'], 'tweet', 'en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9f81b",
   "metadata": {},
   "source": [
    "### Danish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95495c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/danish/data/offenseval-da-training-v1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14838f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3131</td>\n",
       "      <td>Jeg tror det vil være dejlig køligt, men jeg v...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>711</td>\n",
       "      <td>Så kommer de nok til at investere i en ny cyke...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>Nu er det jo også de Ikea-aber der har lavet s...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2678</td>\n",
       "      <td>128 Varme emails, er vi enige om at det er sex...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>784</td>\n",
       "      <td>Desværre tyder det på, at amerikanerne er helt...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet subtask_a\n",
       "0  3131  Jeg tror det vil være dejlig køligt, men jeg v...       NOT\n",
       "1   711  Så kommer de nok til at investere i en ny cyke...       NOT\n",
       "2  2500  Nu er det jo også de Ikea-aber der har lavet s...       OFF\n",
       "3  2678  128 Varme emails, er vi enige om at det er sex...       NOT\n",
       "4   784  Desværre tyder det på, at amerikanerne er helt...       NOT"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d1771",
   "metadata": {},
   "source": [
    "#### 1. Word Frequency for tweets that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab80da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 384 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lort', 45),\n",
       " ('@USER', 31),\n",
       " ('bare', 29),\n",
       " ('  ', 24),\n",
       " ('godt', 22),\n",
       " ('fandme', 22),\n",
       " ('når', 19),\n",
       " ('folk', 19),\n",
       " ('Fuck', 18),\n",
       " ('lortet', 15)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['subtask_a'], ['OFF'], 'tweet', 'da_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e3f59",
   "metadata": {},
   "source": [
    "#### 2. Word Frequency for tweets that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aedc6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 2576 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bare', 147),\n",
       " ('@USER', 126),\n",
       " ('godt', 123),\n",
       " ('når', 121),\n",
       " ('  ', 117),\n",
       " ('Danmark', 100),\n",
       " ('se', 82),\n",
       " ('helt', 81),\n",
       " ('URL', 77),\n",
       " ('år', 74)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['subtask_a'], ['NOT'], 'tweet', 'da_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef9f1d",
   "metadata": {},
   "source": [
    "### Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0466405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/hindi/agr_hi_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "229685d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id', 'text', 'agr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd2097e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>agr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook_corpus_msr_386695</td>\n",
       "      <td>Bhai 60sal pehle desh me kya tha pehle pta kro...</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook_corpus_msr_373389</td>\n",
       "      <td>chutiya friday ko isliye releae krte kyoki wee...</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook_corpus_msr_917635</td>\n",
       "      <td>जय मोदीराज</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook_corpus_msr_382517</td>\n",
       "      <td>UPA walo ne bahot kuch kr diya tha desh k liye</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook_corpus_msr_403274</td>\n",
       "      <td>Pan ko Aadhar se link ki zarurat kuy hai? Supr...</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0  facebook_corpus_msr_386695   \n",
       "1  facebook_corpus_msr_373389   \n",
       "2  facebook_corpus_msr_917635   \n",
       "3  facebook_corpus_msr_382517   \n",
       "4  facebook_corpus_msr_403274   \n",
       "\n",
       "                                                text  agr  \n",
       "0  Bhai 60sal pehle desh me kya tha pehle pta kro...  CAG  \n",
       "1  chutiya friday ko isliye releae krte kyoki wee...  CAG  \n",
       "2                                         जय मोदीराज  CAG  \n",
       "3     UPA walo ne bahot kuch kr diya tha desh k liye  CAG  \n",
       "4  Pan ko Aadhar se link ki zarurat kuy hai? Supr...  CAG  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['agr'], ['OAG'], 'tweet', 'da_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b232f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsn",
   "language": "python",
   "name": "dsn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
