{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b12cd",
   "metadata": {},
   "source": [
    "# Input Statistical Analysis for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc710333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import emoji\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99ac51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bdee0",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cb58f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "def slice_dataframe_and_compute_word_frequency(df, slice_cols, slice_vals, text_col, spacy_lang_pkg):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    nlp = spacy.load(spacy_lang_pkg)\n",
    "    text = ' '.join(sliced_df[text_col])\n",
    "    text = emoji.get_emoji_regexp().sub(r'', text)\n",
    "    doc = nlp(text)\n",
    "    words = [token.text for token in doc if not token.is_stop and not token.is_punct and len(token) > 1]\n",
    "    freqs = Counter(words)\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e43de",
   "metadata": {},
   "source": [
    "### Spanish (Basile et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4404d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/spanish-basile/hateval2019_es_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f94b94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>Easyjet quiere duplicar el número de mujeres p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>El gobierno debe crear un control estricto de ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>Yo veo a mujeres destruidas por acoso laboral ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>— Yo soy respetuoso con los demás, sólamente l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20007</td>\n",
       "      <td>Antonio Caballero y como ser de mal gusto e ig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  HS  TR  AG\n",
       "0  20001  Easyjet quiere duplicar el número de mujeres p...   1   0   0\n",
       "1  20002  El gobierno debe crear un control estricto de ...   1   0   0\n",
       "2  20003  Yo veo a mujeres destruidas por acoso laboral ...   0   0   0\n",
       "3  20004  — Yo soy respetuoso con los demás, sólamente l...   0   0   0\n",
       "4  20007  Antonio Caballero y como ser de mal gusto e ig...   0   0   0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a40bd9",
   "metadata": {},
   "source": [
    "#### 1.1 Word Frequecy for Examples that are Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fb85351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 1857 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 418),\n",
       " ('perra', 345),\n",
       " ('zorra', 216),\n",
       " ('Cállate', 122),\n",
       " ('callate', 110),\n",
       " ('inmigrantes', 102),\n",
       " ('mujer', 96),\n",
       " ('Callate', 91),\n",
       " ('mereces', 82),\n",
       " ('cállate', 78)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [1], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73769e52",
   "metadata": {},
   "source": [
    "#### 1.2 Word Frequecy for Examples that are Hate Speech and Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1286b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 1502 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 398),\n",
       " ('perra', 322),\n",
       " ('zorra', 207),\n",
       " ('Cállate', 122),\n",
       " ('callate', 109),\n",
       " ('Callate', 90),\n",
       " ('mereces', 80),\n",
       " ('cállate', 78),\n",
       " ('mierda', 74),\n",
       " ('PUTA', 67)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS', 'AG'], [1, 1], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ca5fe",
   "metadata": {},
   "source": [
    "#### 1.3 Word Frequecy for Examples that are Hate Speech but not Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5f31b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 355 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mujer', 54),\n",
       " ('inmigrantes', 36),\n",
       " ('mujeres', 32),\n",
       " ('subsaharianos', 23),\n",
       " ('perra', 23),\n",
       " ('puta', 20),\n",
       " ('España', 17),\n",
       " ('país', 17),\n",
       " ('papeles', 16),\n",
       " ('inmigrante', 15)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS', 'AG'], [1, 0], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251dbec",
   "metadata": {},
   "source": [
    "#### 2.  Word Frequecy for Examples that are not Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8142d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 2643 examples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('puta', 784),\n",
       " ('hijo', 237),\n",
       " ('acoso', 198),\n",
       " ('madre', 149),\n",
       " ('perra', 142),\n",
       " ('polla', 141),\n",
       " ('PUTA', 139),\n",
       " ('mierda', 117),\n",
       " ('mereces', 112),\n",
       " ('violación', 110)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = slice_dataframe_and_compute_word_frequency(df, ['HS'], [0], 'text', 'es_core_news_sm')\n",
    "freqs.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865072e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsn",
   "language": "python",
   "name": "dsn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
