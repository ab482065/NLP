{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-dataset Sentiment Analysis for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Nicholas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/all-translated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_dataframe_and_compute_sentiment(df, slice_cols, slice_vals):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    text = ' '.join(sliced_df['translated_text'])\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Sentiment For Hateful Labels in English Basile dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'{DATA_DIR}/B_english_basile_processed.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(slice_dataframe_and_compute_sentiment(df, ['hs'], [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment for all hateful datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/all-translated\\T_B_arabic_mulki_processed.csv\n",
      "Found a total of 468 examples\n",
      "{'neg': 0.067, 'neu': 0.841, 'pos': 0.093, 'compound': 0.9992}\n",
      "../data/all-translated\\T_B_danish_processed.csv\n",
      "Found a total of 425 examples\n",
      "{'neg': 0.193, 'neu': 0.652, 'pos': 0.155, 'compound': -0.9999}\n",
      "../data/all-translated\\T_B_french_ousidhoum_processed.csv\n",
      "Found a total of 207 examples\n",
      "{'neg': 0.156, 'neu': 0.76, 'pos': 0.084, 'compound': -0.9995}\n",
      "../data/all-translated\\T_B_german_bretschneider_processed.csv\n",
      "Found a total of 1331 examples\n",
      "{'neg': 0.164, 'neu': 0.702, 'pos': 0.134, 'compound': -1.0}\n",
      "../data/all-translated\\T_B_german_ross_processed.csv\n",
      "Found a total of 105 examples\n",
      "{'neg': 0.191, 'neu': 0.708, 'pos': 0.101, 'compound': -0.9994}\n",
      "../data/all-translated\\T_B_indonesian_alfina_processed.csv\n",
      "Found a total of 260 examples\n",
      "{'neg': 0.14, 'neu': 0.735, 'pos': 0.125, 'compound': -0.9978}\n",
      "../data/all-translated\\T_B_italian_manuel_processed.csv\n",
      "Found a total of 843 examples\n",
      "{'neg': 0.188, 'neu': 0.733, 'pos': 0.08, 'compound': -1.0}\n"
     ]
    }
   ],
   "source": [
    "hateful_sentiment_dict = {}\n",
    "for path in glob.glob(DATA_DIR + '/*.csv'):\n",
    "    path_in_str = str(path)\n",
    "    print(path_in_str)\n",
    "    df = pd.read_csv(path_in_str)\n",
    "    hateful_sentiment_dict[path_in_str] = slice_dataframe_and_compute_sentiment(df, ['hs'], [1])\n",
    "    print(hateful_sentiment_dict[path_in_str])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment for all normal labels in hateful datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/all-translated\\T_B_arabic_mulki_processed.csv\n",
      "Found a total of 3649 examples\n",
      "{'neg': 0.06, 'neu': 0.808, 'pos': 0.133, 'compound': 1.0}\n",
      "../data/all-translated\\T_B_danish_processed.csv\n",
      "Found a total of 2850 examples\n",
      "{'neg': 0.1, 'neu': 0.714, 'pos': 0.185, 'compound': 1.0}\n",
      "../data/all-translated\\T_B_french_ousidhoum_processed.csv\n",
      "Found a total of 821 examples\n",
      "{'neg': 0.143, 'neu': 0.721, 'pos': 0.137, 'compound': -0.999}\n",
      "../data/all-translated\\T_B_german_bretschneider_processed.csv\n",
      "Found a total of 5141 examples\n",
      "{'neg': 0.128, 'neu': 0.702, 'pos': 0.169, 'compound': 1.0}\n",
      "../data/all-translated\\T_B_german_ross_processed.csv\n",
      "Found a total of 364 examples\n",
      "{'neg': 0.148, 'neu': 0.737, 'pos': 0.115, 'compound': -0.9996}\n",
      "../data/all-translated\\T_B_indonesian_alfina_processed.csv\n",
      "Found a total of 453 examples\n",
      "{'neg': 0.059, 'neu': 0.707, 'pos': 0.234, 'compound': 1.0}\n",
      "../data/all-translated\\T_B_italian_manuel_processed.csv\n",
      "Found a total of 4436 examples\n",
      "{'neg': 0.169, 'neu': 0.751, 'pos': 0.08, 'compound': -1.0}\n"
     ]
    }
   ],
   "source": [
    "non_hateful_sentiment_dict = {}\n",
    "for path in glob.glob(DATA_DIR + '/*.csv'):\n",
    "    path_in_str = str(path)\n",
    "    print(path_in_str)\n",
    "    df = pd.read_csv(path_in_str)\n",
    "    non_hateful_sentiment_dict[path_in_str] = slice_dataframe_and_compute_sentiment(df, ['hs'], [0])\n",
    "    print(non_hateful_sentiment_dict[path_in_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing sentiment for hate speech v non hatespeech\n",
      "For ../data/all-translated\\T_B_arabic_mulki_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.067 v 0.06, Neu: 0.841 v 0.808, Pos: 0.093 v 0.133)\n",
      "For ../data/all-translated\\T_B_danish_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.193 v 0.1, Neu: 0.652 v 0.714, Pos: 0.155 v 0.185)\n",
      "For ../data/all-translated\\T_B_french_ousidhoum_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.156 v 0.143, Neu: 0.76 v 0.721, Pos: 0.084 v 0.137)\n",
      "For ../data/all-translated\\T_B_german_bretschneider_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.164 v 0.128, Neu: 0.702 v 0.702, Pos: 0.134 v 0.169)\n",
      "For ../data/all-translated\\T_B_german_ross_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.191 v 0.148, Neu: 0.708 v 0.737, Pos: 0.101 v 0.115)\n",
      "For ../data/all-translated\\T_B_indonesian_alfina_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.14 v 0.059, Neu: 0.735 v 0.707, Pos: 0.125 v 0.234)\n",
      "For ../data/all-translated\\T_B_italian_manuel_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.188 v 0.169, Neu: 0.733 v 0.751, Pos: 0.08 v 0.08)\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing sentiment for hate speech v non hatespeech\")\n",
    "for dataset in hateful_sentiment_dict:\n",
    "    if dataset in non_hateful_sentiment_dict:\n",
    "        print(\"For {}, \\n \\t HSvNormal: (Neg: {} v {}, Neu: {} v {}, Pos: {} v {})\".format(dataset,\n",
    "         hateful_sentiment_dict[dataset]['neg'], non_hateful_sentiment_dict[dataset]['neg'], \n",
    "         hateful_sentiment_dict[dataset]['neu'], non_hateful_sentiment_dict[dataset]['neu'], \n",
    "         hateful_sentiment_dict[dataset]['pos'], non_hateful_sentiment_dict[dataset]['pos'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b9210e76c871583b4be282bfe8fe4a35092a039f09ad1ca55e305e87262e8ac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ai_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
