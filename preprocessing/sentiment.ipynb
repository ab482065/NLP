{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-dataset Input Statistical Analysis for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Nicholas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/all-processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_dataframe_and_compute_sentiment(df, slice_cols, slice_vals):\n",
    "    sliced_df = df.copy()\n",
    "    for i in range(len(slice_cols)):\n",
    "        sliced_df = sliced_df[sliced_df[slice_cols[i]] == slice_vals[i]]\n",
    "    print(f'Found a total of {len(sliced_df)} examples')\n",
    "    text = ' '.join(sliced_df['text'])\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Sentiment For Hateful Labels in English Basile dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurray , saving us $ $ $ many ways @ potus @ r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would young fighting age men vast majority one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ kamalaharris illegals dump kids border like ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ny times : 'nearly white ' states pose 'an arr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orban brussels : european leaders ignoring peo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  hs\n",
       "0  hurray , saving us $ $ $ many ways @ potus @ r...   1\n",
       "1  would young fighting age men vast majority one...   1\n",
       "2  @ kamalaharris illegals dump kids border like ...   1\n",
       "3  ny times : 'nearly white ' states pose 'an arr...   0\n",
       "4  orban brussels : european leaders ignoring peo...   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA_DIR}/B_english_basile_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 5470 examples\n",
      "{'neg': 0.361, 'neu': 0.517, 'pos': 0.121, 'compound': -1.0}\n"
     ]
    }
   ],
   "source": [
    "print(slice_dataframe_and_compute_sentiment(df, ['hs'], [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment for all hateful datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/all-processed\\B_arabic_mulki_processed.csv\n",
      "Found a total of 468 examples\n",
      "{'neg': 0.001, 'neu': 0.981, 'pos': 0.019, 'compound': 0.9988}\n",
      "../data/all-processed\\B_danish_processed.csv\n",
      "Found a total of 425 examples\n",
      "{'neg': 0.066, 'neu': 0.894, 'pos': 0.041, 'compound': -0.9997}\n",
      "../data/all-processed\\B_english_basile_processed.csv\n",
      "Found a total of 5470 examples\n",
      "{'neg': 0.361, 'neu': 0.517, 'pos': 0.121, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_davidson_processed.csv\n",
      "Found a total of 1430 examples\n",
      "{'neg': 0.359, 'neu': 0.542, 'pos': 0.099, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_founta_processed.csv\n",
      "Found a total of 2075 examples\n",
      "{'neg': 0.297, 'neu': 0.603, 'pos': 0.101, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_gilbert_processed.csv\n",
      "Found a total of 1196 examples\n",
      "{'neg': 0.186, 'neu': 0.66, 'pos': 0.154, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_ousidhoum_processed.csv\n",
      "Found a total of 1278 examples\n",
      "{'neg': 0.317, 'neu': 0.572, 'pos': 0.111, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_waseem_processed.csv\n",
      "Found a total of 2759 examples\n",
      "{'neg': 0.131, 'neu': 0.743, 'pos': 0.126, 'compound': -0.9998}\n",
      "../data/all-processed\\B_french_ousidhoum_processed.csv\n",
      "Found a total of 207 examples\n",
      "{'neg': 0.037, 'neu': 0.95, 'pos': 0.013, 'compound': -0.9937}\n",
      "../data/all-processed\\B_german_bretschneider_processed.csv\n",
      "Found a total of 1331 examples\n",
      "{'neg': 0.015, 'neu': 0.974, 'pos': 0.011, 'compound': -0.9968}\n",
      "../data/all-processed\\B_german_ross_processed.csv\n",
      "Found a total of 105 examples\n",
      "{'neg': 0.039, 'neu': 0.935, 'pos': 0.026, 'compound': -0.9713}\n",
      "../data/all-processed\\B_indonesian_alfina_processed.csv\n",
      "Found a total of 260 examples\n",
      "{'neg': 0.019, 'neu': 0.964, 'pos': 0.018, 'compound': 0.5615}\n",
      "../data/all-processed\\B_indonesian_ibrohim_processed.csv\n",
      "Found a total of 5561 examples\n",
      "{'neg': 0.014, 'neu': 0.974, 'pos': 0.013, 'compound': -0.9946}\n",
      "../data/all-processed\\B_italian_bosco_processed.csv\n",
      "Found a total of 2766 examples\n",
      "{'neg': 0.016, 'neu': 0.977, 'pos': 0.007, 'compound': -0.9999}\n",
      "../data/all-processed\\B_italian_manuel_processed.csv\n",
      "Found a total of 843 examples\n",
      "{'neg': 0.009, 'neu': 0.98, 'pos': 0.011, 'compound': 0.9603}\n",
      "../data/all-processed\\B_portuguese_processed.csv\n",
      "Found a total of 1228 examples\n",
      "{'neg': 0.007, 'neu': 0.974, 'pos': 0.019, 'compound': 0.9993}\n",
      "../data/all-processed\\B_spanish_basile_processed.csv\n",
      "Found a total of 2739 examples\n",
      "{'neg': 0.006, 'neu': 0.98, 'pos': 0.013, 'compound': 0.9996}\n",
      "../data/all-processed\\B_spanish_pereira_processed.csv\n",
      "Found a total of 1567 examples\n",
      "{'neg': 0.01, 'neu': 0.971, 'pos': 0.019, 'compound': 0.9991}\n",
      "../data/all-processed\\B_turkish_processed.csv\n",
      "Found a total of 6757 examples\n",
      "{'neg': 0.005, 'neu': 0.99, 'pos': 0.005, 'compound': 0.9969}\n"
     ]
    }
   ],
   "source": [
    "hateful_sentiment_dict = {}\n",
    "for path in glob.glob('../data/all-processed/*.csv'):\n",
    "    path_in_str = str(path)\n",
    "    print(path_in_str)\n",
    "    df = pd.read_csv(path_in_str)\n",
    "    hateful_sentiment_dict[path_in_str] = slice_dataframe_and_compute_sentiment(df, ['hs'], [1])\n",
    "    print(hateful_sentiment_dict[path_in_str])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment for all normal labels in hateful datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/all-processed\\B_arabic_mulki_processed.csv\n",
      "Found a total of 3649 examples\n",
      "{'neg': 0.001, 'neu': 0.974, 'pos': 0.025, 'compound': 1.0}\n",
      "../data/all-processed\\B_danish_processed.csv\n",
      "../data/all-processed\\B_english_basile_processed.csv\n",
      "Found a total of 7530 examples\n",
      "{'neg': 0.222, 'neu': 0.646, 'pos': 0.132, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_davidson_processed.csv\n",
      "Found a total of 4163 examples\n",
      "{'neg': 0.085, 'neu': 0.785, 'pos': 0.13, 'compound': 1.0}\n",
      "../data/all-processed\\B_english_founta_processed.csv\n",
      "Found a total of 34487 examples\n",
      "{'neg': 0.111, 'neu': 0.68, 'pos': 0.209, 'compound': 1.0}\n",
      "../data/all-processed\\B_english_gilbert_processed.csv\n",
      "Found a total of 9507 examples\n",
      "{'neg': 0.118, 'neu': 0.708, 'pos': 0.174, 'compound': 1.0}\n",
      "../data/all-processed\\B_english_ousidhoum_processed.csv\n",
      "Found a total of 4369 examples\n",
      "{'neg': 0.291, 'neu': 0.59, 'pos': 0.119, 'compound': -1.0}\n",
      "../data/all-processed\\B_english_waseem_processed.csv\n",
      "Found a total of 7679 examples\n",
      "{'neg': 0.101, 'neu': 0.765, 'pos': 0.134, 'compound': 1.0}\n",
      "../data/all-processed\\B_french_ousidhoum_processed.csv\n",
      "Found a total of 821 examples\n",
      "{'neg': 0.044, 'neu': 0.943, 'pos': 0.013, 'compound': -0.9997}\n",
      "../data/all-processed\\B_german_bretschneider_processed.csv\n",
      "../data/all-processed\\B_german_ross_processed.csv\n",
      "Found a total of 364 examples\n",
      "{'neg': 0.013, 'neu': 0.976, 'pos': 0.011, 'compound': -0.9203}\n",
      "../data/all-processed\\B_indonesian_alfina_processed.csv\n",
      "Found a total of 453 examples\n",
      "{'neg': 0.009, 'neu': 0.969, 'pos': 0.022, 'compound': 0.9949}\n",
      "../data/all-processed\\B_indonesian_ibrohim_processed.csv\n",
      "../data/all-processed\\B_italian_bosco_processed.csv\n",
      "Found a total of 4071 examples\n",
      "{'neg': 0.013, 'neu': 0.981, 'pos': 0.005, 'compound': -0.9999}\n",
      "../data/all-processed\\B_italian_manuel_processed.csv\n",
      "Found a total of 4436 examples\n",
      "{'neg': 0.007, 'neu': 0.982, 'pos': 0.011, 'compound': 0.9995}\n",
      "../data/all-processed\\B_portuguese_processed.csv\n",
      "Found a total of 4440 examples\n",
      "{'neg': 0.007, 'neu': 0.977, 'pos': 0.016, 'compound': 0.9999}\n",
      "../data/all-processed\\B_spanish_basile_processed.csv\n",
      "Found a total of 3861 examples\n",
      "{'neg': 0.009, 'neu': 0.974, 'pos': 0.017, 'compound': 0.9999}\n",
      "../data/all-processed\\B_spanish_pereira_processed.csv\n",
      "Found a total of 4433 examples\n",
      "{'neg': 0.008, 'neu': 0.969, 'pos': 0.023, 'compound': 1.0}\n",
      "../data/all-processed\\B_turkish_processed.csv\n",
      "Found a total of 28035 examples\n",
      "{'neg': 0.008, 'neu': 0.983, 'pos': 0.009, 'compound': 0.9999}\n"
     ]
    }
   ],
   "source": [
    "non_hateful_sentiment_dict = {}\n",
    "for path in glob.glob('../data/all-processed/*.csv'):\n",
    "    path_in_str = str(path)\n",
    "    print(path_in_str)\n",
    "    df = pd.read_csv(path_in_str)\n",
    "    if 'danish' not in path_in_str and 'indonesian_ibrohim' not in path_in_str and 'german_bretschneider' not in path_in_str:\n",
    "            non_hateful_sentiment_dict[path_in_str] = slice_dataframe_and_compute_sentiment(df, ['hs'], [0])\n",
    "            print(non_hateful_sentiment_dict[path_in_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing sentiment for hate speech v non hatespeech\n",
      "For ../data/all-processed\\B_arabic_mulki_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.001 v 0.001, Neu: 0.981 v 0.974, Pos: 0.019 v 0.025)\n",
      "For ../data/all-processed\\B_english_basile_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.361 v 0.222, Neu: 0.517 v 0.646, Pos: 0.121 v 0.132)\n",
      "For ../data/all-processed\\B_english_davidson_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.359 v 0.085, Neu: 0.542 v 0.785, Pos: 0.099 v 0.13)\n",
      "For ../data/all-processed\\B_english_founta_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.297 v 0.111, Neu: 0.603 v 0.68, Pos: 0.101 v 0.209)\n",
      "For ../data/all-processed\\B_english_gilbert_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.186 v 0.118, Neu: 0.66 v 0.708, Pos: 0.154 v 0.174)\n",
      "For ../data/all-processed\\B_english_ousidhoum_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.317 v 0.291, Neu: 0.572 v 0.59, Pos: 0.111 v 0.119)\n",
      "For ../data/all-processed\\B_english_waseem_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.131 v 0.101, Neu: 0.743 v 0.765, Pos: 0.126 v 0.134)\n",
      "For ../data/all-processed\\B_french_ousidhoum_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.037 v 0.044, Neu: 0.95 v 0.943, Pos: 0.013 v 0.013)\n",
      "For ../data/all-processed\\B_german_ross_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.039 v 0.013, Neu: 0.935 v 0.976, Pos: 0.026 v 0.011)\n",
      "For ../data/all-processed\\B_indonesian_alfina_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.019 v 0.009, Neu: 0.964 v 0.969, Pos: 0.018 v 0.022)\n",
      "For ../data/all-processed\\B_italian_bosco_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.016 v 0.013, Neu: 0.977 v 0.981, Pos: 0.007 v 0.005)\n",
      "For ../data/all-processed\\B_italian_manuel_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.009 v 0.007, Neu: 0.98 v 0.982, Pos: 0.011 v 0.011)\n",
      "For ../data/all-processed\\B_portuguese_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.007 v 0.007, Neu: 0.974 v 0.977, Pos: 0.019 v 0.016)\n",
      "For ../data/all-processed\\B_spanish_basile_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.006 v 0.009, Neu: 0.98 v 0.974, Pos: 0.013 v 0.017)\n",
      "For ../data/all-processed\\B_spanish_pereira_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.01 v 0.008, Neu: 0.971 v 0.969, Pos: 0.019 v 0.023)\n",
      "For ../data/all-processed\\B_turkish_processed.csv, \n",
      " \t HSvNormal: (Neg: 0.005 v 0.008, Neu: 0.99 v 0.983, Pos: 0.005 v 0.009)\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing sentiment for hate speech v non hatespeech\")\n",
    "for dataset in hateful_sentiment_dict:\n",
    "    if dataset in non_hateful_sentiment_dict:\n",
    "        print(\"For {}, \\n \\t HSvNormal: (Neg: {} v {}, Neu: {} v {}, Pos: {} v {})\".format(dataset,\n",
    "         hateful_sentiment_dict[dataset]['neg'], non_hateful_sentiment_dict[dataset]['neg'], \n",
    "         hateful_sentiment_dict[dataset]['neu'], non_hateful_sentiment_dict[dataset]['neu'], \n",
    "         hateful_sentiment_dict[dataset]['pos'], non_hateful_sentiment_dict[dataset]['pos'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b9210e76c871583b4be282bfe8fe4a35092a039f09ad1ca55e305e87262e8ac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('ai_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
